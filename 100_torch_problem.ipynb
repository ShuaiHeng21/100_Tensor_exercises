{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2016-07-01', '2016-07-02', '2016-07-03', '2016-07-04',\n",
       "       '2016-07-05', '2016-07-06', '2016-07-07', '2016-07-08',\n",
       "       '2016-07-09', '2016-07-10', '2016-07-11', '2016-07-12',\n",
       "       '2016-07-13', '2016-07-14', '2016-07-15', '2016-07-16',\n",
       "       '2016-07-17', '2016-07-18', '2016-07-19', '2016-07-20',\n",
       "       '2016-07-21', '2016-07-22', '2016-07-23', '2016-07-24',\n",
       "       '2016-07-25', '2016-07-26', '2016-07-27', '2016-07-28',\n",
       "       '2016-07-29', '2016-07-30', '2016-07-31'], dtype='datetime64[D]')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-1)\n",
    "np.emath.sqrt(-1) == np.sqrt(-1)\n",
    "yesterday = np.datetime64('today','D') - np.timedelta64(1, 'D')\n",
    "yesterday\n",
    "today = np.datetime64('today','D')\n",
    "tomorrow = np.datetime64('today','D') + np.timedelta64(1, 'D')\n",
    "tomorrow\n",
    "Z = np.arange('2016-07','2016-08',dtype='datetime64[D]')\n",
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. 在不复制值的情况下做原地计算（（A+B）*-(A/2)）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5000, -1.5000, -1.5000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand([3,3])\n",
    "B = torch.rand([3,3])\n",
    "B = A+B\n",
    "B*(-A/2)\n",
    "\n",
    "A = torch.ones(3)*1\n",
    "B = torch.ones(3) * 2\n",
    "torch.add(A,B, out=B)\n",
    "torch.div(A,2, out=A)\n",
    "torch.neg_(A)\n",
    "torch.mul(A, B, out=B)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36. 使用5中不同方法提取Tensor中每个元素的整数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6077, 4.1125],\n",
      "        [3.3231, 2.0427]])\n",
      "1: tensor([[0, 4],\n",
      "        [3, 2]], dtype=torch.int32)\n",
      "2: tensor([[0., 4.],\n",
      "        [3., 2.]])\n",
      "3: tensor([[0., 4.],\n",
      "        [3., 2.]])\n",
      "4: tensor([[0., 4.],\n",
      "        [3., 2.]])\n",
      "5: tensor([[0., 4.],\n",
      "        [3., 2.]])\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [0., 1., 2., 3., 4.],\n",
      "        [0., 1., 2., 3., 4.],\n",
      "        [0., 1., 2., 3., 4.],\n",
      "        [0., 1., 2., 3., 4.]])\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "Z = torch.rand([2,2])*5\n",
    "print(Z)\n",
    "# 1\n",
    "Z1 = Z.int()\n",
    "# Z1 = Z.astype(int)\n",
    "Z1 = Z.type(torch.int)\n",
    "print(\"1:\", Z1)\n",
    "Z2 = torch.floor(Z)\n",
    "print('2:', Z2)\n",
    "Z3 = Z - Z%1\n",
    "print(\"3:\", Z3)\n",
    "Z4 = torch.ceil(Z)-1\n",
    "print(\"4:\", Z4)\n",
    "print(\"5:\", torch.trunc(Z))\n",
    "a = torch.arange(5)\n",
    "# print(a)\n",
    "b = torch.ones([5,5])\n",
    "b[:] = a\n",
    "print(b)\n",
    "print(torch.arange(5).repeat(5,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38. 创建一个生成器函数，用于生成10个整数，并用这个生成器函数创建一个一维Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4328, 0.5807, 0.5709, 0.8513, 0.9274, 0.3693, 0.7886, 0.6507, 0.4391,\n",
      "        0.4993])\n",
      "torch.return_types.sort(\n",
      "values=tensor([0.3693, 0.4328, 0.4391, 0.4993, 0.5709, 0.5807, 0.6507, 0.7886, 0.8513,\n",
      "        0.9274]),\n",
      "indices=tensor([5, 0, 8, 9, 2, 1, 7, 6, 3, 4]))\n",
      "tensor([0.4328, 0.5807, 0.5709, 0.8513, 0.9274, 0.3693, 0.7886, 0.6507, 0.4391,\n",
      "        0.4993])\n",
      "[tensor(0.3693), tensor(0.4328), tensor(0.4391), tensor(0.4993), tensor(0.5709), tensor(0.5807), tensor(0.6507), tensor(0.7886), tensor(0.8513), tensor(0.9274)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([0.3693, 0.4328, 0.4391, 0.4993, 0.5709, 0.5807, 0.6507, 0.7886, 0.8513,\n",
       "        0.9274]),\n",
       "indices=tensor([5, 0, 8, 9, 2, 1, 7, 6, 3, 4]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = (i for i in range(10))\n",
    "tensor = torch.tensor(list(generator))\n",
    "# tensor\n",
    "\n",
    "def g():\n",
    "    yield from range(10)\n",
    "torch.from_numpy(np.fromiter(g(), dtype=np.int))\n",
    "torch.linspace(0,1,12)[1:-1]\n",
    "torch.linspace(0,1,12)[1:-1]\n",
    "a = torch.rand(10)\n",
    "print(a)\n",
    "print(a.sort())\n",
    "a.sort()\n",
    "print(a)\n",
    "print(sorted(a))\n",
    "torch.sort(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41. 对于小向量求和时，如何计算才能比使用np.sum更快？\n",
    "注：在numpy中，可以使用np.add.reduce, 在小向量计算速度上快于np.sum。但pyTorch似乎没有对应的方法，经测试，对torch.arange(10)进行求和时，torch.sum仍然快于np.add.reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001938343048095703\n",
      "0.0008137226104736328\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "Z = np.arange(10)\n",
    "np.add.reduce(Z)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)\n",
    "start_time = time.time()\n",
    "Z = torch.arange(10)\n",
    "torch.sum(Z)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41.给定两个随机TensorA和B，判断是否相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n",
      "tensor(True)\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "A = torch.rand([3,4])\n",
    "B = torch.rand([3,4])\n",
    "C = A\n",
    "print((A == B).sum() == A.numel())\n",
    "print((A == C).sum() == A.numel())\n",
    "# 检查值是否精确相等\n",
    "print(torch.equal(torch.Tensor([1.1, 2.1]), torch.Tensor([1,2])))\n",
    "# torch.Tensor是一个类，而torch.tensor是一个函数\n",
    "# 更经常使用torch.tensor，因为它更方便，有自动的类型转换\n",
    "# 而torch.Tensor确定为torch.float类型\n",
    "print(torch.equal(torch.tensor([1.1, 2.1]), torch.tensor([1, 2], dtype=torch.float)))\n",
    "print(torch.allclose(torch.tensor([1.1,2.1]), torch.tensor([1,2], dtype=torch.float), atol=0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43. 将Tensor转变为只读"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.9924, 0.8430],\n",
      "        [0.3228, 1.4117],\n",
      "        [5.3066, 0.4686],\n",
      "        [1.9566, 0.8032],\n",
      "        [5.5294, 0.9891],\n",
      "        [3.4549, 0.2554],\n",
      "        [5.8452, 0.8802],\n",
      "        [2.3860, 0.0654],\n",
      "        [5.0265, 0.9140],\n",
      "        [2.8753, 1.0491]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.9924, 0.8430],\n",
       "        [0.3228, 1.4117],\n",
       "        [5.3066, 0.4686],\n",
       "        [1.9566, 0.8032],\n",
       "        [5.5294, 0.9891],\n",
       "        [3.4549, 0.2554],\n",
       "        [5.8452, 0.8802],\n",
       "        [2.3860, 0.0654],\n",
       "        [5.0265, 0.9140],\n",
       "        [2.8753, 1.0491]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.zeros(10)\n",
    "Z.flags.writeable = False\n",
    "# Z[0] = 2 # read only -> ValueError\n",
    "A = torch.rand([10,2])*5\n",
    "# print(A)\n",
    "B = torch.zeros([10,2])\n",
    "B[:,0] = torch.sqrt(A.square().sum(dim=1))\n",
    "B[:,1] = torch.arccos(A[:,0]/ B[:,0])\n",
    "print(B)\n",
    "X = A[:,0]\n",
    "Y = A[:,1]\n",
    "R = torch.sqrt(X**2 + Y**2)\n",
    "T = torch.atan(Y/X)\n",
    "torch.stack([R,T],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0642, 0.5919, 0.3882, 0.3786, 0.2815, 0.2714, 0.9014, 0.2193, 0.6944,\n",
      "        0.7569])\n",
      "tensor([0.0642, 0.5919, 0.3882, 0.3786, 0.2815, 0.2714, 0.0000, 0.2193, 0.6944,\n",
      "        0.7569])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 1.0000],\n",
       "        [0.2500, 0.2500, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000],\n",
       "        [0.7500, 0.7500, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(10)\n",
    "print(t)\n",
    "t[torch.argmax(t)] = 0\n",
    "print(t)\n",
    "X = torch.linspace(0,1,5)\n",
    "Z = torch.ones(len(X))\n",
    "coord = torch.stack([X,X,Z],dim=1)\n",
    "coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46. 在直角坐标轴上 (0,0) 到 (1,1) 区域内放一个 5x5 的网格，创建一个5x5x2 的 Tensor，其值对应网格中每个点的坐标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000],\n",
       "         [0.0000, 0.2500],\n",
       "         [0.0000, 0.5000],\n",
       "         [0.0000, 0.7500],\n",
       "         [0.0000, 1.0000]],\n",
       "\n",
       "        [[0.2500, 0.0000],\n",
       "         [0.2500, 0.2500],\n",
       "         [0.2500, 0.5000],\n",
       "         [0.2500, 0.7500],\n",
       "         [0.2500, 1.0000]],\n",
       "\n",
       "        [[0.5000, 0.0000],\n",
       "         [0.5000, 0.2500],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.7500],\n",
       "         [0.5000, 1.0000]],\n",
       "\n",
       "        [[0.7500, 0.0000],\n",
       "         [0.7500, 0.2500],\n",
       "         [0.7500, 0.5000],\n",
       "         [0.7500, 0.7500],\n",
       "         [0.7500, 1.0000]],\n",
       "\n",
       "        [[1.0000, 0.0000],\n",
       "         [1.0000, 0.2500],\n",
       "         [1.0000, 0.5000],\n",
       "         [1.0000, 0.7500],\n",
       "         [1.0000, 1.0000]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = torch.meshgrid(torch.linspace(0,1,5),\n",
    "                     torch.linspace(0,1,5))\n",
    "torch.stack([X,Y],dim=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47. 给定两个向量X,Y, 创建一个柯西矩阵C(Cij=1/(xi-yj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "tensor([[-3., -3., -3., -3., -3.],\n",
      "        [-2., -2., -2., -2., -2.],\n",
      "        [-1., -1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3333, -0.3333, -0.3333, -0.3333, -0.3333],\n",
       "        [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [    inf,     inf,     inf,     inf,     inf],\n",
       "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(5)\n",
    "Y = torch.ones(5)*3\n",
    "C = torch.ones([5,5])\n",
    "X.view([-1,1])\n",
    "print(X.view([-1,1]).shape)\n",
    "print(X.view([-1,1]) - Y)\n",
    "torch.div(1, X.view([-1,1]) - Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48. 打印PyTorch Tensor每一种标量数据结构的最大和最小可表示数(representable value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-128\n",
      "127\n",
      "-2147483648\n",
      "2147483647\n",
      "-9223372036854775808\n",
      "9223372036854775807\n",
      "================\n",
      "-3.4028234663852886e+38\n",
      "3.4028234663852886e+38\n",
      "1.1920928955078125e-07\n",
      "-1.7976931348623157e+308\n",
      "1.7976931348623157e+308\n",
      "2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "for dtype in [torch.int8, torch.int32, torch.int64]:\n",
    "    print(torch.iinfo(dtype).min)\n",
    "    print(torch.iinfo(dtype).max)\n",
    "\n",
    "print(\"==\"*8)\n",
    "for dtype in [torch.float32, torch.float64]:\n",
    "    print(torch.finfo(dtype).min)\n",
    "    print(torch.finfo(dtype).max)\n",
    "    print(torch.finfo(dtype).eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49. 如何完整显示 Tensor 的所有值? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.set_printoptions(threshold=float('NaN'))\n",
    "Z = torch.zeros([16,16])\n",
    "print(Z)\n",
    "torch.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50. 给定一个标量和一个向量，找出向量中与给定标量值最接近的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3931, 0.3437, 0.2906, 0.2759, 0.5262])\n",
      "tensor(0.2759)\n",
      "tensor(0.2759)\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(5)\n",
    "print(t)\n",
    "scalar = 0.08\n",
    "b = torch.square(t-scalar)\n",
    "print(t[torch.argmin(b)])\n",
    "i = torch.abs(t-scalar).argmin()\n",
    "print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "52. 给定一个(100,2)的矩阵，每行表示一个点的坐标。计算所有点两两之间的距离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pointA:tensor([82.4957, 85.4137]), pointB:tensor([22.5277, 94.3432])的距离\n",
      "tensor([[0.0000, 0.9274, 0.4293, 0.5480, 0.4425],\n",
      "        [0.9274, 0.0000, 0.5563, 0.4655, 0.7441],\n",
      "        [0.4293, 0.5563, 0.0000, 0.1189, 0.2234],\n",
      "        [0.5480, 0.4655, 0.1189, 0.0000, 0.2794],\n",
      "        [0.4425, 0.7441, 0.2234, 0.2794, 0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.92742518, 0.42925856, 0.54795354, 0.44251242],\n",
       "       [0.92742518, 0.        , 0.55628736, 0.46553155, 0.74406333],\n",
       "       [0.42925856, 0.55628736, 0.        , 0.11889857, 0.22335627],\n",
       "       [0.54795354, 0.46553155, 0.11889857, 0.        , 0.27939013],\n",
       "       [0.44251242, 0.74406333, 0.22335627, 0.27939013, 0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(100,2)*100\n",
    "def dist_2points(point1, point2):\n",
    "    vec = point2 - point1\n",
    "    return torch.sqrt(torch.square(vec).sum())\n",
    "def dist_2rows(matrix, i, j):\n",
    "    vec1 = matrix[i,:]\n",
    "    vec2 = matrix[j,:]\n",
    "    return dist_2points(vec1, vec2)\n",
    "print(f\"pointA:{A[0,:]}, pointB:{A[5,:]}的距离\")\n",
    "dist_2rows(A, 0, 5)\n",
    "t = torch.rand([5,2])\n",
    "X = t[:,0].view([1,-1])\n",
    "Y = t[:,1].view([1,-1])\n",
    "print(torch.sqrt((X-X.T)**2 + (Y-Y.T)**2))\n",
    "\n",
    "# 第二种，使用scipy\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "D = scipy.spatial.distance.cdist(t,t)\n",
    "D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53. 原地将一个浮点型(32 bits) Tensor 转换为整型(32 bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27 47 86 43  4 59 52 99 71 48]\n"
     ]
    }
   ],
   "source": [
    "Z = (np.random.rand(10)*100).astype(np.float32)\n",
    "Y = Z.view(np.int32)\n",
    "Y[:]=Z\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "54. 将一下内容的Tensor保存至硬盘，并再次读取\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 8,  9,  7],\n",
      "        [10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([[1,2,3],\n",
    "                  [8,9,7],\n",
    "                  [10, 11, 12]])\n",
    "torch.save(T,'tensor.pt')\n",
    "load_tensor = torch.load('tensor.pt')\n",
    "print(load_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55. enumerate 函数在PyTorch中对应的函数是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0) 0\n",
      "(0, 1, 0) 1\n",
      "(0, 2, 0) 2\n",
      "(1, 0, 0) 3\n",
      "(1, 1, 0) 4\n",
      "(1, 2, 0) 5\n",
      "(2, 0, 0) 6\n",
      "(2, 1, 0) 7\n",
      "(2, 2, 0) 8\n",
      "[[0]\n",
      " [1]\n",
      " [2]] 0\n",
      "[[3]\n",
      " [4]\n",
      " [5]] 1\n",
      "[[6]\n",
      " [7]\n",
      " [8]] 2\n"
     ]
    }
   ],
   "source": [
    "Z = np.arange(9).reshape(3,3,1)\n",
    "# ndenumerate 是每一个元素\n",
    "for index, value in np.ndenumerate(Z):\n",
    "    print(index, value)\n",
    "\n",
    "# enumerate 是每一行\n",
    "for index,value in enumerate(Z):\n",
    "    print(value, index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ],\n",
       "        [-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ],\n",
       "        [-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ],\n",
       "        [-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ],\n",
       "        [-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ],\n",
       "        [-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ],\n",
       "        [-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ],\n",
       "        [-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ],\n",
       "        [-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ],\n",
       "        [-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "          0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ]]),\n",
       " array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         -1.        , -1.        , -1.        , -1.        , -1.        ],\n",
       "        [-0.77777778, -0.77777778, -0.77777778, -0.77777778, -0.77777778,\n",
       "         -0.77777778, -0.77777778, -0.77777778, -0.77777778, -0.77777778],\n",
       "        [-0.55555556, -0.55555556, -0.55555556, -0.55555556, -0.55555556,\n",
       "         -0.55555556, -0.55555556, -0.55555556, -0.55555556, -0.55555556],\n",
       "        [-0.33333333, -0.33333333, -0.33333333, -0.33333333, -0.33333333,\n",
       "         -0.33333333, -0.33333333, -0.33333333, -0.33333333, -0.33333333],\n",
       "        [-0.11111111, -0.11111111, -0.11111111, -0.11111111, -0.11111111,\n",
       "         -0.11111111, -0.11111111, -0.11111111, -0.11111111, -0.11111111],\n",
       "        [ 0.11111111,  0.11111111,  0.11111111,  0.11111111,  0.11111111,\n",
       "          0.11111111,  0.11111111,  0.11111111,  0.11111111,  0.11111111],\n",
       "        [ 0.33333333,  0.33333333,  0.33333333,  0.33333333,  0.33333333,\n",
       "          0.33333333,  0.33333333,  0.33333333,  0.33333333,  0.33333333],\n",
       "        [ 0.55555556,  0.55555556,  0.55555556,  0.55555556,  0.55555556,\n",
       "          0.55555556,  0.55555556,  0.55555556,  0.55555556,  0.55555556],\n",
       "        [ 0.77777778,  0.77777778,  0.77777778,  0.77777778,  0.77777778,\n",
       "          0.77777778,  0.77777778,  0.77777778,  0.77777778,  0.77777778],\n",
       "        [ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  1.        ,  1.        ,  1.        ,  1.        ]])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.meshgrid(np.linspace(-1,1,10), np.linspace(-1,1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "57.一个矩阵中随机选p个元素，并替换成其他值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1., 10., 10.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1., 10.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.3733],\n",
       "        [0.0000, 0.0114, 0.0000],\n",
       "        [0.0000, 0.0000, 0.6212]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones([5,5])\n",
    "a = torch.randint(0,5,[3])\n",
    "b = torch.randint(0,5,[3])\n",
    "print(A)\n",
    "A[a,b] = 10\n",
    "print(A)\n",
    "p = 3\n",
    "t = torch.zeros([3,3])\n",
    "indices = torch.from_numpy(np.random.choice(range(9),p))\n",
    "# accumulate在重复索引时，可以累加， 正常就是替换值\n",
    "t.put_(indices, torch.rand(p), accumulate=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58. 给定一个矩阵，计算每个元素减去所在行的平均数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08576638 -0.27017367  0.0054884   0.1885379   0.16191345]\n",
      " [-0.11502016 -0.21105373  0.12959945 -0.23809743  0.43457168]\n",
      " [-0.3463961  -0.35653335 -0.2065599   0.5909062   0.31858307]\n",
      " [ 0.15395665 -0.14002252 -0.17706692 -0.09539092  0.25852346]\n",
      " [ 0.07746977 -0.32236254  0.2367168   0.16645533 -0.15827954]]\n",
      "tensor([[-0.0858, -0.2702,  0.0055,  0.1885,  0.1619],\n",
      "        [-0.1150, -0.2111,  0.1296, -0.2381,  0.4346],\n",
      "        [-0.3464, -0.3565, -0.2066,  0.5909,  0.3186],\n",
      "        [ 0.1540, -0.1400, -0.1771, -0.0954,  0.2585],\n",
      "        [ 0.0775, -0.3224,  0.2367,  0.1665, -0.1583]])\n",
      "nokeepdim, tensor([2., 7.])\n",
      "withkeepdim, tensor([[2.],\n",
      "        [7.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.rand([5,5])\n",
    "A_np = A.numpy()\n",
    "### 注意keepdim=True\n",
    "# 计算列均值\n",
    "col_means = np.mean(A_np, axis=1, keepdims=True)  # 形状 (5,)\n",
    "\n",
    "# 每个元素减去对应行的均值\n",
    "B = A_np - col_means \n",
    "print(B)\n",
    "print(A - torch.mean(A,dim=1, keepdim=True))\n",
    "Y = A - A.mean(axis=1,keepdim=True)\n",
    "Y\n",
    "X = torch.arange(10).view([2,5]).type(torch.float32)\n",
    "print(\"nokeepdim,\" ,torch.mean(X,dim=1))\n",
    "print(\"withkeepdim,\", torch.mean(X,dim=1, keepdim=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "59. 给定一个矩阵，根据第n列的值对行进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([5, 5, 7, 8, 9]),\n",
       "indices=tensor([0, 4, 1, 2, 3]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.randint(0, 10, [5,2])\n",
    "n = 1\n",
    "_, indices = M[:,n].sort()\n",
    "M = M[indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IsaacGym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
